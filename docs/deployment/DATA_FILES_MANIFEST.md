# ğŸ“ Complete Data Files Manifest - Big Mood Detector

This document lists ALL gitignored data files, model weights, and their exact locations for replication.

## ğŸŒ³ Complete Directory Structure

```
big-mood-detector/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cache/                                    # Preprocessed data cache
â”‚   â”‚   â””â”€â”€ nhanes_pat_data_subsetNone.npz      # [CRITICAL] 200MB - Cached training data
â”‚   â”‚
â”‚   â”œâ”€â”€ nhanes/                                   # Raw NHANES data files
â”‚   â”‚   â””â”€â”€ 2013-2014/
â”‚   â”‚       â”œâ”€â”€ DEMO_H.xpt                       # Demographics (3.5MB)
â”‚   â”‚       â”œâ”€â”€ DPQ_H.xpt                        # Depression questionnaire (1.2MB)
â”‚   â”‚       â”œâ”€â”€ PAXDAY_H.xpt                     # Day-level activity (0.8MB)
â”‚   â”‚       â”œâ”€â”€ PAXHD_H.xpt                      # Header data (1.1MB)
â”‚   â”‚       â”œâ”€â”€ PAXMIN_H.xpt                     # [LARGE] Minute activity (1.5GB)
â”‚   â”‚       â”œâ”€â”€ RXQ_DRUG.xpt                     # Drug database (45MB)
â”‚   â”‚       â”œâ”€â”€ RXQ_RX_H.xpt                     # Prescriptions (4.2MB)
â”‚   â”‚       â””â”€â”€ SMQRTU_H.xpt                     # Smoking data (1.8MB)
â”‚   â”‚
â”‚   â”œâ”€â”€ NCHS/                                     # Mortality linkage files
â”‚   â”‚   â””â”€â”€ NHANES_2013_2014_MORT_2019_PUBLIC.dat # Mortality data (2.1MB)
â”‚   â”‚
â”‚   â”œâ”€â”€ baselines/                                # User baseline calibration
â”‚   â”‚   â””â”€â”€ [user_id]/                          # Per-user baseline files (created at runtime)
â”‚   â”‚       â””â”€â”€ baseline_history.json
â”‚   â”‚
â”‚   â””â”€â”€ input/                                    # User health data (optional for testing)
â”‚       â”œâ”€â”€ apple_export/
â”‚       â”‚   â””â”€â”€ export.xml                       # Apple Health export (varies, 100MB-2GB)
â”‚       â””â”€â”€ health_auto_export/
â”‚           â””â”€â”€ *.json                           # JSON exports (varies)
â”‚
â”œâ”€â”€ model_weights/
â”‚   â”œâ”€â”€ xgboost/
â”‚   â”‚   â””â”€â”€ converted/                           # [REQUIRED] XGBoost models
â”‚   â”‚       â”œâ”€â”€ XGBoost_DE.json                  # Depression model (15MB)
â”‚   â”‚       â”œâ”€â”€ XGBoost_HME.json                 # Hypomania model (15MB)
â”‚   â”‚       â””â”€â”€ XGBoost_ME.json                  # Mania model (15MB)
â”‚   â”‚
â”‚   â””â”€â”€ pat/
â”‚       â”œâ”€â”€ pretrained/                          # [REQUIRED] Pretrained PAT weights
â”‚       â”‚   â”œâ”€â”€ PAT-S_29k_weights.h5             # Small model (285KB)
â”‚       â”‚   â”œâ”€â”€ PAT-M_29k_weights.h5             # Medium model (1MB)
â”‚       â”‚   â””â”€â”€ PAT-L_29k_weights.h5             # Large model (1.99MB)
â”‚       â”‚
â”‚       â”œâ”€â”€ heads/                               # Fine-tuned depression heads
â”‚       â”‚   â””â”€â”€ pat_depression_head.pt           # (if trained, ~10MB)
â”‚       â”‚
â”‚       â””â”€â”€ pytorch/                             # PyTorch training outputs
â”‚           â”œâ”€â”€ pat_s_training/
â”‚           â”‚   â”œâ”€â”€ best_stage1_auc_*.pt
â”‚           â”‚   â”œâ”€â”€ best_overall_auc_*.pt
â”‚           â”‚   â””â”€â”€ training_summary.json
â”‚           â”œâ”€â”€ pat_m_training/
â”‚           â”‚   â””â”€â”€ (similar structure)
â”‚           â””â”€â”€ pat_l_training/                  # [IMPORTANT] Current training
â”‚               â”œâ”€â”€ best_stage1_auc_0.5788.pt    # Best checkpoint (8MB)
â”‚               â”œâ”€â”€ checkpoint_migration.pt       # Migration checkpoint
â”‚               â”œâ”€â”€ final_mac_checkpoint.pt       # Final save before migration
â”‚               â”œâ”€â”€ training_summary.json         # Training metadata
â”‚               â””â”€â”€ migration_checkpoint_info.json
â”‚
â””â”€â”€ logs/                                        # Application logs
    â””â”€â”€ *.log                                    # Runtime logs (created automatically)
```

## ğŸ“¦ File Categories by Priority

### ğŸ”´ CRITICAL (App won't run without these)
```
model_weights/xgboost/converted/XGBoost_DE.json
model_weights/xgboost/converted/XGBoost_HME.json  
model_weights/xgboost/converted/XGBoost_ME.json
```

### ğŸŸ¡ IMPORTANT (For PAT functionality)
```
model_weights/pat/pretrained/PAT-S_29k_weights.h5
model_weights/pat/pretrained/PAT-M_29k_weights.h5
model_weights/pat/pretrained/PAT-L_29k_weights.h5
```

### ğŸŸ¢ TRAINING (For continuing PAT training)
```
data/cache/nhanes_pat_data_subsetNone.npz         # Preprocessed data
model_weights/pat/pytorch/pat_l_training/*.pt     # Checkpoints
```

### ğŸ”µ OPTIONAL (For retraining from scratch)
```
data/nhanes/2013-2014/*.xpt                       # Raw NHANES files
data/NCHS/*.dat                                    # Mortality data
```

## ğŸ“Š File Sizes Summary

- **Minimal setup** (XGBoost only): ~45MB
- **With PAT models**: ~48MB  
- **With training cache**: ~250MB
- **Full NHANES raw data**: ~2GB
- **Everything**: ~2.5GB

## ğŸ—‚ï¸ Creating Transfer Archives

```bash
cd ~/Desktop/CLARITY-DIGITAL-TWIN/big-mood-detector

# 1. Essential models only (45MB)
tar -czf essential_models.tar.gz \
  model_weights/xgboost/converted/*.json

# 2. All models including PAT (48MB)
tar -czf all_models.tar.gz \
  model_weights/xgboost/converted/*.json \
  model_weights/pat/pretrained/*.h5

# 3. Training continuation pack (260MB)
tar -czf training_pack.tar.gz \
  data/cache/nhanes_pat_data_subsetNone.npz \
  model_weights/pat/pytorch/pat_l_training/ \
  model_weights/pat/pretrained/*.h5 \
  model_weights/xgboost/converted/*.json

# 4. Complete data archive (2.5GB)
tar -czf complete_data.tar.gz \
  data/cache/ \
  data/nhanes/ \
  data/NCHS/ \
  model_weights/
```

## ğŸ”§ Directory Creation Script

Save this as `create_data_dirs.sh` on your PC:

```bash
#!/bin/bash
# Create all required directories for Big Mood Detector

mkdir -p data/cache
mkdir -p data/nhanes/2013-2014
mkdir -p data/NCHS
mkdir -p data/baselines
mkdir -p data/input/apple_export
mkdir -p data/input/health_auto_export

mkdir -p model_weights/xgboost/converted
mkdir -p model_weights/pat/pretrained
mkdir -p model_weights/pat/heads
mkdir -p model_weights/pat/pytorch/pat_s_training
mkdir -p model_weights/pat/pytorch/pat_m_training
mkdir -p model_weights/pat/pytorch/pat_l_training

mkdir -p logs

echo "âœ… All directories created!"
```

## ğŸŒ Download URLs (if available)

### NHANES Data Files
Base URL: `https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/`
- DEMO_H.XPT
- DPQ_H.XPT
- PAXDAY_H.XPT
- PAXHD_H.XPT
- PAXMIN_H.XPT
- RXQ_RX_H.XPT
- SMQRTU_H.XPT

### NCHS Mortality
URL: `https://ftp.cdc.gov/pub/Health_Statistics/NCHS/datalinkage/linked_mortality/`
- NHANES_2013_2014_MORT_2019_PUBLIC.dat

### Model Weights
- Check GitHub releases or contact maintainers
- XGBoost models are from Seoul National University study
- PAT weights are from Dartmouth's release

## âœ… Verification Commands

After extracting on PC:

```bash
# Check file existence
ls -la model_weights/xgboost/converted/*.json
ls -la model_weights/pat/pretrained/*.h5
ls -la data/cache/*.npz

# Check file sizes
du -sh data/cache/nhanes_pat_data_subsetNone.npz
du -sh model_weights/pat/pytorch/pat_l_training/

# Run setup verification
python scripts/verify_setup.py
```

## ğŸ“ Notes

1. **Paths are case-sensitive** on Mac but not Windows - maintain exact case
2. **Use forward slashes** even on Windows (Python handles conversion)
3. **Create directories first** before extracting archives
4. The `.npz` cache file is **crucial** for training - without it, you need to regenerate from raw XPT files
5. **Git LFS** not used currently - all weights are gitignored

---

This manifest provides complete replication instructions for all data files needed by the Big Mood Detector.