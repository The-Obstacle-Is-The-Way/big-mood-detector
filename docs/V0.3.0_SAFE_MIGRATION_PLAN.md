# V0.3.0 Safe Migration Plan: Professional Approach

**Date:** 2025-07-20  
**Status:** Planning Phase  
**Risk Level:** HIGH - CDS Integration Critical  
**Timeline:** 4-6 weeks estimated

## Executive Summary

This plan ensures zero-downtime migration from v0.2.0 (XGBoost-only predictions) to v0.3.0 (true dual-model ensemble) while maintaining Clinical Decision Support (CDS) integrity. The key challenge is addressing temporal differences: XGBoost forecasts 24 hours ahead while PAT assesses current state.

## Current State Analysis (v0.2.0)

### What Works
- XGBoost predictions: 0.80-0.98 AUC, clinically validated
- PAT embeddings: Enhance XGBoost features
- CDS integration: Expects single risk score
- Docker deployment: Stable production environment

### Critical Issues
1. **Temporal confusion**: Mixing 24-hour forecast with "current state" features
2. **Single prediction output**: CDS expects one risk score, not two
3. **Missing PAT heads**: Cannot make independent PAT predictions yet
4. **Undocumented temporal semantics**: CDS doesn't know if risk is "now" or "tomorrow"

## Migration Strategy: Blue-Green Deployment

### Phase 1: Parallel Development (Week 1-2)
**Goal:** Build v0.3.0 alongside v0.2.0 without touching production

1. **Create feature branch**: `feature/v0.3.0-true-ensemble`
2. **Implement PAT classification heads**:
   ```bash
   cd infrastructure/fine_tuning/
   python train_pat_heads.py --data /data/nhanes/2013-2014/
   ```
3. **Build dual-output prediction interface**:
   ```python
   class TemporalPredictionResult:
       current_state: PATAssessment      # "Now" from PAT
       forecast: XGBoostPrediction       # "Tomorrow" from XGBoost
       unified_risk: float               # Backward-compatible score
   ```

### Phase 2: Testing Infrastructure (Week 2-3)
**Goal:** Comprehensive testing before any production changes

#### 2.1 Create Test Suite
```bash
# New test files needed
tests/migration/
├── test_backward_compatibility.py
├── test_cds_integration.py
├── test_temporal_outputs.py
└── test_performance_regression.py
```

#### 2.2 Performance Benchmarks
```python
# Ensure no degradation
@pytest.mark.benchmark
def test_prediction_latency():
    # v0.2.0: <200ms
    # v0.3.0: Must stay <200ms despite dual models
```

#### 2.3 CDS Contract Testing
```python
# Test existing CDS expects single score
def test_cds_v2_compatibility():
    result = predict_mood_v3(data)
    # New v0.3.0 must provide backward-compatible interface
    assert hasattr(result, 'risk_score')  # Single score for v0.2.0 CDS
    assert 0 <= result.risk_score <= 1
```

### Phase 3: Staged Rollout (Week 3-4)
**Goal:** Gradual deployment with instant rollback capability

#### 3.1 Feature Flags
```python
# config/features.py
FEATURE_FLAGS = {
    "use_pat_predictions": False,      # Start disabled
    "dual_temporal_output": False,     # Start disabled
    "enhanced_cds_format": False,      # Start disabled
}
```

#### 3.2 Canary Deployment
```yaml
# docker-compose.canary.yml
services:
  mood-detector-v2:
    image: mood-detector:v0.2.0
    labels:
      - "traefik.weight=90"  # 90% traffic
  
  mood-detector-v3:
    image: mood-detector:v0.3.0
    labels:
      - "traefik.weight=10"  # 10% traffic
    environment:
      - FEATURE_FLAGS_USE_PAT=false  # Conservative start
```

#### 3.3 Monitoring & Alerts
```python
# monitoring/migration_metrics.py
CRITICAL_METRICS = [
    "prediction_latency_p99",
    "cds_integration_errors",
    "prediction_agreement_rate",  # v0.2.0 vs v0.3.0
    "memory_usage_delta",
]
```

### Phase 4: CDS Evolution (Week 4-5)
**Goal:** Upgrade CDS to leverage temporal insights

#### 4.1 Backward-Compatible API
```python
# v0.3.0 API Response
{
    # Legacy field (required for v0.2.0 CDS)
    "risk_score": 0.72,  # XGBoost 24hr forecast
    
    # New temporal fields (ignored by v0.2.0 CDS)
    "temporal_assessment": {
        "current": {
            "source": "PAT",
            "window": "past_7_days",
            "depression_risk": 0.65,
            "confidence": 0.80,
            "timestamp": "2025-07-20T14:30:00Z"
        },
        "forecast": {
            "source": "XGBoost",
            "window": "next_24_hours", 
            "depression_risk": 0.72,
            "confidence": 0.85,
            "prediction_for": "2025-07-21T14:30:00Z"
        }
    },
    
    # Clinical guidance (new)
    "recommendations": {
        "immediate": "Current state suggests...",
        "preventive": "Tomorrow's risk indicates..."
    }
}
```

#### 4.2 CDS Adapter Pattern
```python
# adapters/cds_adapter.py
class CDSAdapter:
    def __init__(self, cds_version: str):
        self.version = cds_version
    
    def format_prediction(self, result: TemporalPredictionResult):
        if self.version == "v0.2.0":
            # Return single score for legacy CDS
            return {"risk_score": result.unified_risk}
        else:
            # Return rich temporal data for new CDS
            return result.to_temporal_dict()
```

### Phase 5: Full Migration (Week 5-6)
**Goal:** Complete transition with zero downtime

#### 5.1 Pre-Migration Checklist
- [ ] All tests passing (>95% coverage)
- [ ] Performance benchmarks met (<200ms p99)
- [ ] CDS adapter tested with production data
- [ ] Rollback procedure documented and tested
- [ ] Monitoring dashboards configured
- [ ] Team trained on new temporal outputs

#### 5.2 Migration Steps
```bash
# 1. Enable feature flags gradually
curl -X POST api/admin/features \
  -d '{"use_pat_predictions": true, "percentage": 10}'

# 2. Monitor for 24 hours
# Check: prediction_agreement_rate > 0.85

# 3. Increase percentage
# 10% → 25% → 50% → 100%

# 4. Enable dual temporal output
curl -X POST api/admin/features \
  -d '{"dual_temporal_output": true}'

# 5. Update CDS to use new format
# Deploy CDS v2 with temporal awareness
```

## Testing Plan

### 1. Unit Testing
```bash
# Test individual components
pytest tests/domain/ -v
pytest tests/infrastructure/ml_models/ -v
pytest tests/application/use_cases/ -v
```

### 2. Integration Testing
```bash
# Test full pipeline
pytest tests/integration/test_prediction_pipeline.py
pytest tests/integration/test_cds_compatibility.py
```

### 3. System Testing
```bash
# Docker environment
docker-compose -f docker-compose.test.yml up
pytest tests/system/ --docker
```

### 4. Performance Testing
```python
# locustfile.py
class MoodPredictionUser(HttpUser):
    @task
    def predict_mood(self):
        self.client.post("/api/v1/predict", json={
            "user_id": "test_user",
            "data": generate_test_data()
        })
```

### 5. Chaos Testing
```bash
# Test resilience
# 1. Kill PAT model process - should fallback to XGBoost only
# 2. Introduce latency - should timeout gracefully
# 3. Corrupt model weights - should use cached version
```

## Risk Mitigation

### High-Risk Areas
1. **CDS Integration Breaking**
   - Mitigation: Adapter pattern + extensive contract testing
   - Rollback: Feature flag to disable new format instantly

2. **Performance Degradation**
   - Mitigation: Aggressive caching + model optimization
   - Rollback: Circuit breaker to skip PAT if slow

3. **Temporal Confusion**
   - Mitigation: Clear labeling + documentation
   - Rollback: Revert to single prediction mode

### Rollback Procedure
```bash
# Immediate rollback (< 1 minute)
curl -X POST api/admin/rollback -d '{"version": "v0.2.0"}'

# This will:
# 1. Disable all v0.3.0 feature flags
# 2. Route 100% traffic to v0.2.0 containers
# 3. Alert on-call team
# 4. Create incident report
```

## Success Criteria

### Technical Metrics
- [ ] Zero downtime during migration
- [ ] Prediction latency <200ms (p99)
- [ ] Memory usage increase <20%
- [ ] Test coverage >95%
- [ ] Zero CDS integration errors

### Clinical Metrics
- [ ] Prediction accuracy maintained or improved
- [ ] Temporal predictions correctly labeled
- [ ] Clinical recommendations appropriate
- [ ] User feedback positive

## Communication Plan

### Stakeholders
1. **Clinical Team**: Weekly updates on temporal model benefits
2. **DevOps**: Daily sync during migration week
3. **Users**: In-app notification about enhanced predictions
4. **On-call**: Special procedures during migration

### Documentation Updates
- [ ] API documentation with temporal fields
- [ ] CDS integration guide v2
- [ ] Clinical interpretation guide
- [ ] Troubleshooting runbook

## Post-Migration

### Week 1 After Migration
- Daily performance reviews
- User feedback collection
- Fine-tune feature flags
- Address any edge cases

### Month 1 After Migration
- Full performance analysis
- Clinical outcome review
- Plan next enhancements
- Document lessons learned

## Appendix: Key Commands

```bash
# Development
make test-migration     # Run migration test suite
make benchmark         # Performance comparison
make canary-deploy     # Start canary deployment

# Monitoring
kubectl logs -f deployment/mood-detector-v3
curl api/metrics | grep prediction_latency

# Rollback
make rollback-v2       # Emergency rollback
```

---

*"Slow is smooth, smooth is fast" - Professional teams migrate safely.*